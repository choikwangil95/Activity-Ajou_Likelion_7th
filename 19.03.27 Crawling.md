# Crawling
- 모듈 : 프로그램의 꾸러미로 package임 / 따라서 만들어진 모듈을 사용하는 것이 편하다
- 모듈 설치하기 -> pip install 모듈이름
- 모듈 가져오기 -> from 모듈 import 함수
- 모듈 사용하기 -> 사용해 그냥
```python
from urllib.request import urlopen # 이거는 urlopen 함수를 import 해주는것
from bs4 import BeautifulSoup # bs4로 파이썬이 알수있는 객채로 만들어주는것

url = "https://music.bugs.co.kr/chart"
html = urlopen(url)
source = html.read() # 바이트코드 type으로 소스를 읽는다.
html.close() # urlopen을 진행한 후에는 close를 한다.

soup = BeautifulSoup(source, "html.parser") # 파싱할 문서를 BeautifulSoup 클래스의 생성자에 넘겨주어 문서 개체를 생성, 관습적으로 soup 이라 부름

table =soup.find("tbody")
songs = table.find_all(class_="left")
songlist=['벅스 음원 차트']

rank=1
for song in songs:
   
    title = song.get_text()
    title = title.replace("\n", "")  
    songlist.append('위 : {}'.format(title))
    print('{}위 : {}'.format(rank,title))
    rank +=1
    if rank == 101:
        break

import pandas as pd

data = pd.DataFrame(songlist)
header=['순위, 노래제목']
data.to_csv('bugs_chart.csv',encoding='utf-16',header=header)
```
