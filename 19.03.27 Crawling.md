# 멋쟁이 사자처럼 수업
## Crawling
#### 모듈 : 프로그램의 꾸러미로 package임 / 따라서 만들어진 모듈을 사용하는 것이 편하다<br/>
- 모듈 설치하기 -> pip install 모듈이름<br/>
- 모듈 가져오기 -> from 모듈 import 함수<br/>
- 모듈 사용하기 -> 사용해 그냥<br/>
- 사용한 모듈 : request, bs4, pandas<br/>
#### pandas : 파이썬을 통해 데이터분석을 할 때 분석을 하기 위한 라이브러리 중 하나로 dataframe을 가공하는 것.
#### Request : urlopen 라이브러리를 통해 웹을 연다.
#### BeautifulSoup : html을 python이 이해하는 객체 구조로 만들어주는 parsing을 맡고있는 라이브러리<br/>
####                 이 라이브러리를 이용해 우리는 제대로 된 ‘의미있는’ 정보를 추출해 낼 수 있다.
   (여기서 파싱(Parsing)은 어떤 페이지(문서, html 등)에서 내가 원하는 데이터를 특정 패턴이나 순서로 추출하여 
    정보로 가공하는 것을 말하는 것이다 )
#### 모듈 가져오기
```python
from urllib.request import urlopen 
from bs4 import BeautifulSoup 
```
#### 웹에 있는 소스 가져오기
```python
url = "https://music.bugs.co.kr/chart"
html = urlopen(url)
source = html.read() # 바이트코드 type으로 소스를 읽는다.
html.close() # urlopen을 진행한 후에는 close를 한다.
soup = BeautifulSoup(source, "html.parser") 
# 파싱할 문서를 BeautifulSoup 클래스의 생성자에 넘겨주어 문서 개체를 생성, 관습적으로 soup 이라 부름
```
#### 웹에 있는 소스 중 원하는 소스 선택하기
```python
# 웹에 있는 소스 중 원하는 소스 선택하기
table =soup.find("tbody")
songs = table.find_all(class_="left")
songlist=['벅스 음원 차트']
# name = soup.select(h3>a) 특정 html 문장을 선택하는 것
```
#### 정보 가공하기
```python
rank=1
for song in songs:
   
    title = song.get_text()
    title = title.replace("\n", "")  
    songlist.append('위 : {}'.format(title))
    print('{}위 : {}'.format(rank,title))
    rank +=1
    if rank == 101:
        break
```
#### dataframe 가공하기
```python
import pandas as pd

data = pd.DataFrame(songlist)
header=['순위, 노래제목']
data.to_csv('bugs_chart.csv',encoding='utf-16',header=header)
```
## Login
#### Selenium은 주로 웹앱을 테스트하는데 이용하는 프레임워크다.<br/>
#### webdriver라는 API를 통해 운영체제에 설치된 Chrome등의 브라우저를 제어하게 된다.(Chromedriver를 설치해야한다)
